{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSIM_image_retrival.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNpD0n23r9GMbHV5jvCyTIP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "from shutil import copyfile\n",
        "import cv2 as cv\n",
        "from google.colab.patches import cv2_imshow\n",
        "from cv2 import CascadeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import image as kimage\n",
        "from tensorflow.keras.applications import mobilenet_v2\n",
        "from sklearn.neighbors import KDTree\n",
        "import joblib"
      ],
      "metadata": {
        "id": "J2BBYAhNzjGL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset "
      ],
      "metadata": {
        "id": "ed3YIh8Cyxx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "VIPs dataset"
      ],
      "metadata": {
        "id": "xYUcALMeH8Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Link Google Drive account, transfer dataset, and extract files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "copyfile('gdrive/My Drive/vip.zip', 'vip.zip')\n",
        "zip = zipfile.ZipFile('vip.zip')\n",
        "zip.extractall()\n",
        "zip.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-2JPqJAyxbj",
        "outputId": "271b2609-fbe1-4056-801c-78eae00381c8"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data loader + face detection"
      ],
      "metadata": {
        "id": "W3XFsAfoIzAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def face_detection(img):\n",
        "    # funzione che data un'immagine ritorna solamente il crop della faccia che trova al suo interno\n",
        "    classifier = CascadeClassifier('/haarcascade_frontalface_default.xml')\n",
        "    box = classifier.detectMultiScale(img, minNeighbors=20)\n",
        "    #se non trova nessuna faccia non ritorna niente\n",
        "    (x,y,w,h) = (0,0,0,0)\n",
        "    if box is ():\n",
        "        return None\n",
        "    #altrimenti ritorna solo la prima faccia\n",
        "    else:\n",
        "        (x,y,w,h) = box[0]\n",
        "        return cv.resize(img[y:y+h, x:x+w, :], (224,224))"
      ],
      "metadata": {
        "id": "Q5TIrziSIMgj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "    # funzione che per con le immagini crea il dataset di train e test applicando prima la funzione di face detection\n",
        "    root = '/content/thumbnails_features_deduped_publish'\n",
        "\n",
        "    paths = []\n",
        "    images = []\n",
        "\n",
        "    for folder in sorted(os.listdir(root)):\n",
        "    #dalla cartella principale apro solo le cartelle (no file .txt etc.)\n",
        "        if not os.path.isfile(root + \"/\" + folder):\n",
        "            for file in sorted(os.listdir(root + \"/\" + folder)):\n",
        "            # per ogni foto che trovo nelle cartelle vips, opero face detection e salvo il risultato\n",
        "                if file.endswith('.jpg'):\n",
        "                    img = cv.imread(root + \"/\" + folder + \"/\" + file)\n",
        "                    img = (face_detection(img))\n",
        "                    #se il face detector trova un'immagine allora la aggiunge al dataset\n",
        "                    if img is not None:\n",
        "                        #preprocessing\n",
        "                        img = kimage.img_to_array(img)\n",
        "                        img = keras.applications.mobilenet_v2.preprocess_input(img)\n",
        "                        img = np.expand_dims(img, axis=0)\n",
        "                        images.append(img)\n",
        "                        # lable\n",
        "                        paths.append(root + \"/\" + folder + \"/\" + file)\n",
        "    return images, paths"
      ],
      "metadata": {
        "id": "DNhkWmyzI9ui"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, paths = load_data()"
      ],
      "metadata": {
        "id": "sVonFwzILdGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature extraction"
      ],
      "metadata": {
        "id": "FWMofS8pO3GS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "net = keras.applications.MobileNetV2(input_shape=(224,224,3), weights='imagenet', include_top=False, pooling='max')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "oLk1bcm3O45M",
        "outputId": "b999bea7-fdf3-41ee-a7b6-272fb352d977"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7773d1ce2794>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMobileNetV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature extraction"
      ],
      "metadata": {
        "id": "y62kP7JFxD5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = list(map(lambda x: (net.predict(x)).flatten(), X_train))\n",
        "X_train = np.array(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "RBaS38ZX0R-6",
        "outputId": "e7a4beb5-ad8b-4f67-e5bc-a86e1830810b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e6511f24a49d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build KD-Tree"
      ],
      "metadata": {
        "id": "npua-RLB1f3P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = KDTree(X_train)"
      ],
      "metadata": {
        "id": "lDogcefM07fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image to query"
      ],
      "metadata": {
        "id": "QPtHg29_14Xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_image = cv.imread(\"/content/thumbnails_features_deduped_publish/50 cent/0.jpg\")\n",
        "cv2_imshow(query_image)"
      ],
      "metadata": {
        "id": "o3AZ7Q6F1tFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing query"
      ],
      "metadata": {
        "id": "U2ziDrkr2R0v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_image = face_detection(query_image)\n",
        "query_features = kimage.img_to_array(query_image)\n",
        "query_features = keras.applications.mobilenet_v2.preprocess_input(query_features)\n",
        "query_features = np.expand_dims(query_features, axis=0)\n",
        "query_features = (net.predict(query_features)).flatten()\n",
        "query_features = np.expand_dims(query_features, axis=0)"
      ],
      "metadata": {
        "id": "8RBvAuOa2H77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ricerca query_image nel KDTree e mostra i num_simil risultati pi√π simili"
      ],
      "metadata": {
        "id": "qwWYWVOp3bwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, ind = tree.query(query_features, k=10)"
      ],
      "metadata": {
        "id": "L2BBCgvW3fdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_simil = 5\n",
        "for i in range(0,5):\n",
        "    kimage.load_img(paths[ind[0][i]])"
      ],
      "metadata": {
        "id": "8xGeuVfM3nhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Salvataggio del KDTree"
      ],
      "metadata": {
        "id": "VB8yrVFK4Y4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the search tree\n",
        "joblib.dump(tree, 'kdtree.joblib')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "lFIhzvOh4bO5",
        "outputId": "086a202d-1fe6-40d7-db71-b22e10877e12"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f88564c2c03a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Saving the search tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kdtree.joblib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'joblib' is not defined"
          ]
        }
      ]
    }
  ]
}